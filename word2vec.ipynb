{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.kaggle.com/api/v1/datasets/download/emirhanai/2024-u-s-election-sentiment-on-x'\n",
    "\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved as 'dataset.zip'\n"
     ]
    }
   ],
   "source": [
    "if response.status_code == 200:\n",
    "    with open('dataset.zip', 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(\"Dataset saved as 'dataset.zip'\")\n",
    "else:\n",
    "    print(f\"Error downloading dataset: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset unpacked as 'dataset'\n"
     ]
    }
   ],
   "source": [
    "with zipfile.ZipFile('dataset.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('dataset')\n",
    "print(\"Dataset unpacked as 'dataset'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset files: ['test.csv', 'train.csv', 'val.csv']\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir('dataset')\n",
    "print(\"Dataset files:\", files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train size: 500\n",
      "df_test size: 50\n",
      "df_val size: 50\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('dataset/train.csv')\n",
    "df_test = pd.read_csv('dataset/test.csv')\n",
    "df_val = pd.read_csv('dataset/val.csv')\n",
    "\n",
    "print(f\"df_train size: {df_train.shape[0]}\")\n",
    "print(f\"df_test size: {df_test.shape[0]}\")\n",
    "print(f\"df_val size: {df_val.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>user_handle</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>candidate</th>\n",
       "      <th>party</th>\n",
       "      <th>retweets</th>\n",
       "      <th>likes</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@user123</td>\n",
       "      <td>2024-11-03 08:45:00</td>\n",
       "      <td>Excited to see Kamala Harris leading the Democ...</td>\n",
       "      <td>Kamala Harris</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>120</td>\n",
       "      <td>450</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@politicsFan</td>\n",
       "      <td>2024-11-03 09:15:23</td>\n",
       "      <td>Donald Trump's policies are the best for our e...</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican Party</td>\n",
       "      <td>85</td>\n",
       "      <td>300</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>@greenAdvocate</td>\n",
       "      <td>2024-11-03 10:05:45</td>\n",
       "      <td>Jill Stein's environmental plans are exactly w...</td>\n",
       "      <td>Jill Stein</td>\n",
       "      <td>Green Party</td>\n",
       "      <td>60</td>\n",
       "      <td>200</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@indieVoice</td>\n",
       "      <td>2024-11-03 11:20:10</td>\n",
       "      <td>Robert Kennedy offers a fresh perspective outs...</td>\n",
       "      <td>Robert Kennedy</td>\n",
       "      <td>Independent</td>\n",
       "      <td>40</td>\n",
       "      <td>150</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>@libertyLover</td>\n",
       "      <td>2024-11-03 12:35:55</td>\n",
       "      <td>Chase Oliver's libertarian stance promotes tru...</td>\n",
       "      <td>Chase Oliver</td>\n",
       "      <td>Libertarian Party</td>\n",
       "      <td>30</td>\n",
       "      <td>120</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id     user_handle            timestamp  \\\n",
       "0         1        @user123  2024-11-03 08:45:00   \n",
       "1         2    @politicsFan  2024-11-03 09:15:23   \n",
       "2         3  @greenAdvocate  2024-11-03 10:05:45   \n",
       "3         4     @indieVoice  2024-11-03 11:20:10   \n",
       "4         5   @libertyLover  2024-11-03 12:35:55   \n",
       "\n",
       "                                          tweet_text       candidate  \\\n",
       "0  Excited to see Kamala Harris leading the Democ...   Kamala Harris   \n",
       "1  Donald Trump's policies are the best for our e...    Donald Trump   \n",
       "2  Jill Stein's environmental plans are exactly w...      Jill Stein   \n",
       "3  Robert Kennedy offers a fresh perspective outs...  Robert Kennedy   \n",
       "4  Chase Oliver's libertarian stance promotes tru...    Chase Oliver   \n",
       "\n",
       "               party  retweets  likes sentiment  \n",
       "0   Democratic Party       120    450  positive  \n",
       "1   Republican Party        85    300  positive  \n",
       "2        Green Party        60    200  positive  \n",
       "3        Independent        40    150   neutral  \n",
       "4  Libertarian Party        30    120  positive  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m fig \u001b[38;5;241m=\u001b[39m px\u001b[38;5;241m.\u001b[39mbar(df_train, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparty\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlikes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/nlp/word2vec/.venv/lib/python3.12/site-packages/plotly/basedatatypes.py:3410\u001b[0m, in \u001b[0;36mBaseFigure.show\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3377\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3378\u001b[0m \u001b[38;5;124;03mShow a figure using either the default renderer(s) or the renderer(s)\u001b[39;00m\n\u001b[1;32m   3379\u001b[0m \u001b[38;5;124;03mspecified by the renderer argument\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3406\u001b[0m \u001b[38;5;124;03mNone\u001b[39;00m\n\u001b[1;32m   3407\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3408\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpio\u001b[39;00m\n\u001b[0;32m-> 3410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/nlp/word2vec/.venv/lib/python3.12/site-packages/plotly/io/_renderers.py:394\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(fig, renderer, validate, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    390\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m         )\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nbformat \u001b[38;5;129;01mor\u001b[39;00m Version(nbformat\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4.2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 394\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    395\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    396\u001b[0m         )\n\u001b[1;32m    398\u001b[0m     ipython_display\u001b[38;5;241m.\u001b[39mdisplay(bundle, raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    400\u001b[0m \u001b[38;5;66;03m# external renderers\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
     ]
    }
   ],
   "source": [
    "fig = px.bar(df_train, x='party', y='likes')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/jose/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jose/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jose/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import hunspell\n",
    "# Make sure that python-dev and libhunspell-dev are installed.\n",
    "#   $ sudo apt-get update\n",
    "#   $ sudo apt-get install python-dev \n",
    "#   $ sudo apt-get install libhunspell-dev\n",
    "#   $ sudo pip install hunspell\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "spell_checker = hunspell.HunSpell('dictionaries/index.dic', 'dictionaries/index.aff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['natural', 'language', 'processing', 'field', 'artificial', 'intelligence', 'deal', 'interaction', 'computer', 'human', 'natural', 'language', 'check', 'article', 'information']\n"
     ]
    }
   ],
   "source": [
    "def preprocess(input):\n",
    "    # Whitespace removal\n",
    "    text = input.strip()          # Leading and trailing\n",
    "    text = \" \".join(text.split()) # Remove multiplied whitespaces\n",
    "\n",
    "    # URL removal\n",
    "    pattern = r\"(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?\"\n",
    "    text = re.sub(pattern, \"\", text)\n",
    "\n",
    "    # Tokenization (separating words into a list of tokens)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # Lowercasing (removing Uppercase letters)\n",
    "    lowercased_tokens = [token.lower() for token in tokens]\n",
    "\n",
    "    # Filtering punctuation\n",
    "    filtered_tokens = [token for token in lowercased_tokens if token not in string.punctuation]\n",
    "\n",
    "    # Stopword removal (removing words with little value such as 'the' 'of' etc.)\n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "    filtered_tokens = [token for token in filtered_tokens if token.lower() not in stopwords]\n",
    "\n",
    "    # Spelling correction (using the hunspell library)\n",
    "    corrected_tokens = []\n",
    "    for token in filtered_tokens:\n",
    "            # Check if the word is misspelled\n",
    "            if not spell_checker.spell(token):\n",
    "                # Try to suggest corrections\n",
    "                suggestions = spell_checker.suggest(token)\n",
    "                if suggestions:\n",
    "                    corrected_tokens.append(suggestions[0])  # Choose the first suggestion\n",
    "                else:\n",
    "                    corrected_tokens.append(token)  # No suggestions, keep the original token\n",
    "            else:\n",
    "                corrected_tokens.append(token)\n",
    "\n",
    "    # Lemmatization (reducing words to their lemma form)\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    processed_tokens = [lemmatizer.lemmatize(token) for token in corrected_tokens]\n",
    "\n",
    "    return processed_tokens\n",
    "\n",
    "example = \"Naturalf languagde processiang is a field of artificial inteligence that deals with the interaction between computers and human (natural) language. Check out this article for more information: https://en.wikipedia.org/wiki/Natural_language_processing\"\n",
    "print(preprocess(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
